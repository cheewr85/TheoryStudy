# Memory
## 메인 메모리(main memory)

> 각각 주소가 할당된 일련의 바이트로 구성됨
> CPU는 Program Counter가 가르키는 대로 메모리로부터 다음 명령어를 가져옴

### MMU
- 명령어를 수행할 때 메모리 안에 필요한 데이터가 없으면 그 데이터를 가져오는 역할을 하는 것이 Memory Management Unit, MMU
- MMU는 논리 주소를 물리 주소로 변환하고 메모리 부호와 캐시 관리와 같이 CPU가 메모리에 접근하는 것을 지원해주는 장치
- 가상 주소에서 실제 데이터가 빠르게 접근하도록 도움 
- CPU가 매번 메인 메모리에 직접적으로 접근하는 것이 비효율적이고, 속도가 느리므로 캐시 메모리 이용

또한 메인 메모리의 직접 접근은 비효율적이므로, CPU와 메인 메모리 속도를 맞추기 위해 캐시가 존재함

### MMU의 메모리 보호
프로세스가 접근 가능한 합법적인 주소 영역을 할당해주고, 허용되지 않은 접근은 trap을 발생시켜 보호

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2F5Lgut%2FbtquNvKMRwH%2FJOqzcmz8wiXf0Kv7okfGzK%2Fimg.png">

base와 limit 레지스터를 활용한 메모리 보호 기법
- base 레지스터 : 메모리상의 프로세스 시작주소를 물리 주소로 저장
- limit 레지스터 : 프로세스의 사이즈를 저장
- 프로세스가 접근 가능한 메모리 영역, x : base <= x < base+limit
- 위 영역 밖에서는 trap 발생

안전성을 위해 base와 limit 레지스터는 사용자 모드가 아닌, 커널 모드에서만 수정 가능

### 메모리 과할당(over allocating)
> 실제 메모리의 사이즈보다 더 큰 사이즈의 메모리를 프로세스에 할당한 상황

- 페이지 기법: 사용자가 눈치 채지 못하도록 눈속임을 통해 가상 메모리를 할당
-  과할당 상황이 문제가 되는 경우
	1. 프로세스 실행 도중 페이지 폴트 발생
	2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음
	3. 메모리의 빈 프레임에 페이지를 올려야 하는데, 모든 메모리가 사용중이라 빈 프레임이 없음

- 과할당 해결 방법 : 빈 프레임 확보
	1. 메모리에 올라와 있는 한 프로세스를 종료하여 프레임 회수 : 안정성 떨어짐
	2. 프로세스 하나를 swap out하고, 이 공간을 빈 프레임으로 활용 = 페이지 교체
	
	Swap:메모리에서 보조기억장치(HDD나 SSD)에 임시로 저장해두는 것 (swaping in , swaping out) -> 공간을 바꿔치기
	1번 방법은 페이징 시스템을 들킬 가능성이 매우 높아서 하면 안됨

사용자에게 들킨다는 것 -> 사용자의 눈에 멀티프로그래밍으로 보이지 않는 것

즉 페이징을 통해 메인 메모리에 필요 프로세스가 모두 올려져 있어서 공간 문제 없이 잘 돌아가는 것 처럼 보이게 하는 것을 눈을 속인다고 하는 것

###  페이지 교체

> 메모리 과할당이 발생했을 때, 프로세스 하나를 swap out해서 빈 프레임을 확보하는 것

1. 프로세스 실행 도중 페이지 부재 발생
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음
3. 메모리에 빈 프레임이 있는지 확인
4. 빈 프레임이 있으면 해당 프레임을 사용 
5. 빈 프레임이 없으면, victim 프레임을 선정해 디스크에 기록하고 페이지 테이블을 업데이트함
6. 빈 프레임에 페이지 폴트가 발생한 페이지를 올리고, 페이지 테이블 업데이트


> 페이지 교체를 통해 여러 프로세스가 계속 돌아가게 하고 사용자가 교체되고 있음을 알지 못하도록 해야 함
> 페이지 교체의 오버헤드를 줄여 퍼포먼스 향상


### 오버헤드 감소
- 이처럼 빈 프레임이 없는 상황에서 victim 프레임을 비울 때와 원하는 페이지를 프레임으로 올릴 때 두 번의 디스크 접근이 이루어짐
- 페이지 교체가 많이 이루어지면, 이처럼 입출력 연산이 많이 발생하게 되면서 오버헤드 문제가 발생함

- 방법1
	- 변경비트를 모든 페이지마다 둬서, victim 페이지가 정해지면 해당 페이지의 비트를 확인
	- 해당 비트가 set 상태 → 해당 페이지 내용이 디스크 상의 페이지 내용과 달라졌으므로 디스크에 갱신
	- bit가 clear 상태 → 디스크 상의 페이지 내용과 메모리 상의 페이지가 정확히 일치하는 상황
	- 비트를 활용해  디스크에 기록하는 횟수를 줄이면서 오버헤드에 대한 수를 최대 절반으로 감소시키는 방법임
- 방법2
	- 상황마다 적합한 페이지 교체 알고리즘 활용
	- 페이지 폴트 발생 상황 최소화
		- FIFO
		- OPT
		- LRU

### 캐시 메모리

> 주기억장치에 저장된 내용의 일부를 임시로 저장해두는 기억장치
>
> CPU와 주기억장치의 속도 차이로 성능 저하를 방지하기 위한 방법
- CPU가 이미 참조했던 주소에  재접근할 때, 메모리 참조 및 인출 과정에 대한 비용을 줄이기 위해 캐시에 저장해둔 데이터를 활용
- 캐시는 플리플롭 소자로 구성된 SRAM으로. DRAM보다 빠름

### CPU와 기억장치의 상호작용
> CPU에서 주소를 전달 → 캐시 기억장치에 명령이 존재하는지 확인
- (존재) Hit → 해당 명령어를 CPU로 전송 → 완료
- (비존재) Miss → 명령어를 갖고 주기억장치로 접근 → 해당 명령어를 가진 데이터 인출 → 해당 명령어 데이터를 캐시에 저장 → 해당 명령어를 CPU로 전송 → 완료
- 캐시의 효율 : CPU가 어떤 데이터를 원할지 얼마나 잘 예측하는가 - 높은 히트율(적중률)
- 적중률 증대는 지역성의 원리를 활용

### 지역성

> 기억 장치 내의 정보를 균일하게 액세스 하는 것이 아니라 한 순간에 특정 부분을 집중적으로 참조하는 특성

**시간 지역성** : 최근에 참조된 주소의 내용은 곧 다음에도 참조되는 특성

**공간 지역성** : 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성


### 캐싱 라인
캐싱 라인 : 캐시에 데이터를 저장할 때, Set이나 Map 등의 자료구조를 활용하여, 데이터와 데이터의 메모리 주소를 함께 저장

캐시를 가장 효율적으로 활용하려면, 캐시 내에서도 여러 데이터를 거쳐 원하는 데이터를 얻는 것 보다 바로 해당 데이터에 접근하는 것이 중요함
